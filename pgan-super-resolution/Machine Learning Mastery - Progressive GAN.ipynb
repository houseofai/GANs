{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! Le generateur ne progresse pas et les discriminateurs sont a zeros tous les deux\n",
    "\n",
    "Cela peut etre du a la conversion en tensorflow 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import time\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of progressive growing gan on celebrity faces dataset\n",
    "from math import sqrt\n",
    "from numpy import load\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from skimage.transform import resize\n",
    "from matplotlib import pyplot\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted sum output\n",
    "class WeightedSum(layers.Add):\n",
    "    # init with default value\n",
    "    def __init__(self, alpha=0.0, **kwargs):\n",
    "        super(WeightedSum, self).__init__(**kwargs)\n",
    "        self.alpha = tf.Variable(alpha, name='ws_alpha')\n",
    "\n",
    "    # output a weighted sum of inputs\n",
    "    def _merge_function(self, inputs):\n",
    "        # only supports a weighted sum of two inputs\n",
    "        assert (len(inputs) == 2)\n",
    "        # ((1-a) * input1) + (a * input2)\n",
    "        output = ((1.0 - self.alpha) * inputs[0]) + (self.alpha * inputs[1])\n",
    "        return output\n",
    "    \n",
    "    #def get_config(self):\n",
    "#\n",
    "#        config = super().get_config().copy()\n",
    "#        config.update({\n",
    "#            'alpha': self.alpha\n",
    "#        })\n",
    "#        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate wasserstein loss\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return tf.math.reduce_mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a discriminator block\n",
    "def add_discriminator_block(old_model, n_input_layers=3):\n",
    "    # get shape of existing model\n",
    "    in_shape = list(old_model.input.shape)\n",
    "    # define new input shape as double the size\n",
    "    input_shape = (in_shape[-2]*2, in_shape[-2]*2, in_shape[-1])\n",
    "    in_image = layers.Input(shape=input_shape)\n",
    "    # define new input processing layer\n",
    "    d = layers.Conv2D(64, (1,1), padding='same', kernel_initializer='he_normal')(in_image)\n",
    "    d = layers.LeakyReLU(alpha=0.2)(d)\n",
    "    # define new block\n",
    "    d = layers.Conv2D(64, (3,3), padding='same', kernel_initializer='he_normal')(d)\n",
    "    d = layers.BatchNormalization()(d)\n",
    "    d = layers.LeakyReLU(alpha=0.2)(d)\n",
    "    d = layers.Conv2D(64, (3,3), padding='same', kernel_initializer='he_normal')(d)\n",
    "    d = layers.BatchNormalization()(d)\n",
    "    d = layers.LeakyReLU(alpha=0.2)(d)\n",
    "    d = layers.AveragePooling2D()(d)\n",
    "    block_new = d\n",
    "    # skip the input, 1x1 and activation for the old model\n",
    "    for i in range(n_input_layers, len(old_model.layers)):\n",
    "        d = old_model.layers[i](d)\n",
    "    # define straight-through model\n",
    "    model1 = keras.models.Model(in_image, d)\n",
    "    # compile model\n",
    "    model1.compile(loss='mse', optimizer=optimizers.Adam(lr=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
    "    # downsample the new larger image\n",
    "    downsample = layers.AveragePooling2D()(in_image)\n",
    "    # connect old input processing to downsampled new input\n",
    "    block_old = old_model.layers[1](downsample)\n",
    "    block_old = old_model.layers[2](block_old)\n",
    "    # fade in output of old model input layer with new input\n",
    "    d = WeightedSum()([block_old, block_new])\n",
    "    # skip the input, 1x1 and activation for the old model\n",
    "    for i in range(n_input_layers, len(old_model.layers)):\n",
    "        d = old_model.layers[i](d)\n",
    "    # define straight-through model\n",
    "    model2 = keras.models.Model(in_image, d)\n",
    "    # compile model\n",
    "    model2.compile(loss='mse', optimizer=optimizers.Adam(lr=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
    "    return [model1, model2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the discriminator models for each image resolution\n",
    "def define_discriminator(n_blocks, input_shape=(4,4,3)):\n",
    "    print('Building the Discriminator')\n",
    "    model_list = list()\n",
    "    # base model input\n",
    "    in_image = layers.Input(shape=input_shape)\n",
    "    # conv 1x1\n",
    "    d = layers.Conv2D(64, (1,1), padding='same', kernel_initializer='he_normal')(in_image)\n",
    "    d = layers.LeakyReLU(alpha=0.2)(d)\n",
    "    # conv 3x3 (output block)\n",
    "    d = layers.Conv2D(128, (3,3), padding='same', kernel_initializer='he_normal')(d)\n",
    "    d = layers.BatchNormalization()(d)\n",
    "    d = layers.LeakyReLU(alpha=0.2)(d)\n",
    "    # conv 4x4\n",
    "    d = layers.Conv2D(128, (4,4), padding='same', kernel_initializer='he_normal')(d)\n",
    "    d = layers.BatchNormalization()(d)\n",
    "    d = layers.LeakyReLU(alpha=0.2)(d)\n",
    "    # dense output layer\n",
    "    d = layers.Flatten()(d)\n",
    "    out_class = layers.Dense(1)(d)\n",
    "    # define model\n",
    "    model = keras.models.Model(in_image, out_class)\n",
    "    # compile model\n",
    "    model.compile(loss='mse', optimizer=optimizers.Adam(lr=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
    "    # store model\n",
    "    model_list.append([model, model])\n",
    "    # create submodels\n",
    "    for i in range(1, n_blocks):\n",
    "        # get prior model without the fade-on\n",
    "        old_model = model_list[i - 1][0]\n",
    "        # create new model for next resolution\n",
    "        models = add_discriminator_block(old_model)\n",
    "        # store model\n",
    "        model_list.append(models)\n",
    "    print('* Discriminator built')\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a generator block\n",
    "def add_generator_block(old_model):\n",
    "    # get the end of the last block\n",
    "    block_end = old_model.layers[-2].output\n",
    "    # upsample, and define new block\n",
    "    upsampling = layers.UpSampling2D()(block_end)\n",
    "    g = layers.Conv2D(64, (3,3), padding='same', kernel_initializer='he_normal')(upsampling)\n",
    "    g = layers.BatchNormalization()(g)\n",
    "    g = layers.LeakyReLU(alpha=0.2)(g)\n",
    "    g = layers.Conv2D(64, (3,3), padding='same', kernel_initializer='he_normal')(g)\n",
    "    g = layers.BatchNormalization()(g)\n",
    "    g = layers.LeakyReLU(alpha=0.2)(g)\n",
    "    # add new output layer\n",
    "    out_image = layers.Conv2D(3, (1,1), padding='same', kernel_initializer='he_normal')(g)\n",
    "    # define model\n",
    "    model1 = keras.models.Model(old_model.input, out_image)\n",
    "    # get the output layer from old model\n",
    "    out_old = old_model.layers[-1]\n",
    "    # connect the upsampling to the old output layer\n",
    "    out_image2 = out_old(upsampling)\n",
    "    # define new output image as the weighted sum of the old and new models\n",
    "    merged = WeightedSum()([out_image2, out_image])\n",
    "    # define model\n",
    "    model2 = keras.models.Model(old_model.input, merged)\n",
    "    return [model1, model2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define generator models\n",
    "def define_generator(latent_dim, n_blocks, in_dim=4):\n",
    "    print('Building the Generator')\n",
    "    model_list = list()\n",
    "    # base model latent input\n",
    "    in_latent = layers.Input(shape=(latent_dim,))\n",
    "    # linear scale up to activation maps\n",
    "    g  = layers.Dense(128 * in_dim * in_dim, kernel_initializer='he_normal')(in_latent)\n",
    "    g = layers.Reshape((in_dim, in_dim, 128))(g)\n",
    "    # conv 4x4, input block\n",
    "    g = layers.Conv2D(128, (3,3), padding='same', kernel_initializer='he_normal')(g)\n",
    "    g = layers.BatchNormalization()(g)\n",
    "    g = layers.LeakyReLU(alpha=0.2)(g)\n",
    "    # conv 3x3\n",
    "    g = layers.Conv2D(128, (3,3), padding='same', kernel_initializer='he_normal')(g)\n",
    "    g = layers.BatchNormalization()(g)\n",
    "    g = layers.LeakyReLU(alpha=0.2)(g)\n",
    "    # conv 1x1, output block\n",
    "    out_image = layers.Conv2D(3, (1,1), padding='same', kernel_initializer='he_normal')(g)\n",
    "    # define model\n",
    "    model = keras.models.Model(in_latent, out_image)\n",
    "    # store model\n",
    "    model_list.append([model, model])\n",
    "    # create submodels\n",
    "    for i in range(1, n_blocks):\n",
    "        # get prior model without the fade-on\n",
    "        old_model = model_list[i - 1][0]\n",
    "        # create new model for next resolution\n",
    "        models = add_generator_block(old_model)\n",
    "        # store model\n",
    "        model_list.append(models)\n",
    "    print('* Generator built')\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define composite models for training generators via discriminators\n",
    "def define_composite(discriminators, generators):\n",
    "    model_list = list()\n",
    "    # create composite models\n",
    "    for i in range(len(discriminators)):\n",
    "        g_models, d_models = generators[i], discriminators[i]\n",
    "        # straight-through model\n",
    "        d_models[0].trainable = False\n",
    "        model1 = tf.keras.Sequential()\n",
    "        model1.add(g_models[0])\n",
    "        model1.add(d_models[0])\n",
    "        model1.compile(loss='mse', optimizer=optimizers.Adam(lr=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
    "        # fade-in model\n",
    "        d_models[1].trainable = False\n",
    "        model2 = tf.keras.Sequential()\n",
    "        model2.add(g_models[1])\n",
    "        model2.add(d_models[1])\n",
    "        model2.compile(loss='mse', optimizer=optimizers.Adam(lr=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
    "        # store\n",
    "        model_list.append([model1, model2])\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "def load_real_samples(filename):\n",
    "    # load dataset\n",
    "    data = load(filename)\n",
    "    # extract numpy array\n",
    "    X = data['arr_0']\n",
    "    # convert from ints to floats\n",
    "    X = X.astype('float32')\n",
    "    # scale from [0,255] to [-1,1]\n",
    "    X = (X - 127.5) / 127.5\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    # choose random instances\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    # select images\n",
    "    X = dataset[ix]\n",
    "    # generate class labels\n",
    "    y = ones((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    # generate points in the latent space\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    # generate points in latent space\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    # predict outputs\n",
    "    X = generator.predict(x_input)\n",
    "    # create class labels\n",
    "    y = -ones((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the alpha value on each instance of WeightedSum\n",
    "def update_fadein(models, step, n_steps):\n",
    "    # calculate current alpha (linear from 0 to 1)\n",
    "    alpha = step / float(n_steps - 1)\n",
    "    # update the alpha for each model\n",
    "    for model in models:\n",
    "        for layer in model.layers:\n",
    "            if isinstance(layer, WeightedSum):\n",
    "                #tf.set_value(layer.alpha, alpha)\n",
    "                #layer.alpha.assign(alpha)\n",
    "                keras.backend.set_value(layer.alpha, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a generator and discriminator\n",
    "def train_epochs(g_model, d_model, gan_model, dataset, n_epochs, n_batch, fadein=False):\n",
    "    # calculate the number of batches per training epoch\n",
    "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "    # calculate the number of training iterations\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    # calculate the size of half a batch of samples\n",
    "    half_batch = int(n_batch / 2)\n",
    "    # manually enumerate epochs\n",
    "    print('* Batch per epoch:', bat_per_epo)\n",
    "    print('* Steps:', n_steps)\n",
    "    pbar = trange(n_steps, desc='Epoch runs', leave=True)\n",
    "    for i in pbar:\n",
    "        # update alpha for all WeightedSum layers when fading in new blocks\n",
    "        if fadein:\n",
    "            update_fadein([g_model, d_model, gan_model], i, n_steps)\n",
    "        # prepare real and fake samples\n",
    "        X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "        X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "        # update discriminator model\n",
    "        d_loss1 = d_model.train_on_batch(X_real, y_real)\n",
    "        d_loss2 = d_model.train_on_batch(X_fake, y_fake)\n",
    "        # update the generator via the discriminator's error\n",
    "        z_input = generate_latent_points(latent_dim, n_batch)\n",
    "        y_real2 = ones((n_batch, 1))\n",
    "        g_loss = gan_model.train_on_batch(z_input, y_real2)\n",
    "        # summarize loss on this batch\n",
    "        #t.set_description('>{}, d1={0.3f}, d2={0.3f} g={0.3f}'.format(i+1, d_loss1, d_loss2, g_loss), refresh=True)\n",
    "        pbar.set_postfix({'d1':\"%.3f\" % d_loss1, 'd2': \"%.3f\" % d_loss2, 'g':\"%.3f\" % g_loss})\n",
    "        #print('>%d, d1=%.3f, d2=%.3f g=%.3f' % (i+1, d_loss1, d_loss2, g_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale images to preferred size\n",
    "def scale_dataset(images, new_shape):\n",
    "    images_list = list()\n",
    "    print('Scaling image from {} to {}'.format(images[0].shape, new_shape))\n",
    "    for image in tqdm(images):\n",
    "        # resize with nearest neighbor interpolation\n",
    "        new_image = resize(image, new_shape, 0)\n",
    "        # store\n",
    "        images_list.append(new_image)\n",
    "        \n",
    "    print('Images scaled')\n",
    "    return asarray(images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate samples and save as a plot and save the model\n",
    "def summarize_performance(status, g_model, latent_dim, n_samples=25):\n",
    "    print(\"Summarize Performance\")\n",
    "    # devise name\n",
    "    gen_shape = g_model.output_shape\n",
    "    name = '%03dx%03d-%s' % (gen_shape[1], gen_shape[2], status)\n",
    "    # generate images\n",
    "    X, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "    # normalize pixel values to the range [0,1]\n",
    "    X = (X - X.min()) / (X.max() - X.min())\n",
    "    # plot real images\n",
    "    square = int(sqrt(n_samples))\n",
    "    for i in range(n_samples):\n",
    "        pyplot.subplot(square, square, 1 + i)\n",
    "        pyplot.axis('off')\n",
    "        pyplot.imshow(X[i])\n",
    "    pyplot.show()\n",
    "    # save plot to file\n",
    "    filename1 = 'plot_%s.png' % (name)\n",
    "    pyplot.savefig(filename1)\n",
    "    pyplot.close()\n",
    "    # save the generator model\n",
    "    filename2 = 'model_%s.h5' % (name)\n",
    "    g_model.save(filename2)\n",
    "    print('>Saved: %s and %s' % (filename1, filename2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the generator and discriminator\n",
    "def train(g_models, d_models, gan_models, dataset, latent_dim, e_norm, e_fadein, n_batch):\n",
    "    print(\"fit the baseline model\")\n",
    "    g_normal, d_normal, gan_normal = g_models[0][0], d_models[0][0], gan_models[0][0]\n",
    "    print(\"scale dataset to appropriate size:\", g_normal.output_shape[1:])\n",
    "    gen_shape = g_normal.output_shape\n",
    "    scaled_data = scale_dataset(dataset, gen_shape[1:])\n",
    "    print(\"train normal or straight-through models. Norm: {} - Batch: {}\".format(e_norm[0], n_batch[0]))\n",
    "    train_epochs(g_normal, d_normal, gan_normal, scaled_data, e_norm[0], n_batch[0])\n",
    "    summarize_performance('tuned', g_normal, latent_dim)\n",
    "    print(\"process each level of growth. Nb of levels:\".format(len(g_models)))\n",
    "    for i in range(1, len(g_models)):\n",
    "        # retrieve models for this level of growth\n",
    "        [g_normal, g_fadein] = g_models[i]\n",
    "        [d_normal, d_fadein] = d_models[i]\n",
    "        [gan_normal, gan_fadein] = gan_models[i]\n",
    "        # scale dataset to appropriate size\n",
    "        gen_shape = g_normal.output_shape\n",
    "        scaled_data = scale_dataset(dataset, gen_shape[1:])\n",
    "        print('Scaled Data', scaled_data.shape)\n",
    "        # train fade-in models for next level of growth\n",
    "        train_epochs(g_fadein, d_fadein, gan_fadein, scaled_data, e_fadein[i], n_batch[i], True)\n",
    "        summarize_performance('faded', g_fadein, latent_dim)\n",
    "        # train normal or straight-through models\n",
    "        train_epochs(g_normal, d_normal, gan_normal, scaled_data, e_norm[i], n_batch[i])\n",
    "        summarize_performance('tuned', g_normal, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the Discriminator\n",
      "* Discriminator built\n"
     ]
    }
   ],
   "source": [
    "# number of growth phases, e.g. 9 == [4, 8, 16, 32, 64, 128, 512, 1024, 2048]\n",
    "n_blocks = 6\n",
    "# size of the latent space\n",
    "latent_dim = 100\n",
    "# define models\n",
    "d_models = define_discriminator(n_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define models\n",
    "g_models = define_generator(latent_dim, n_blocks)\n",
    "# define composite models\n",
    "gan_models = define_composite(d_models, g_models)\n",
    "# load image data\n",
    "dataset = load_real_samples('img_align_celeba_128.npz')\n",
    "print('Loaded', dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the prepared dataset\n",
    "from numpy import load\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# plot a list of loaded faces\n",
    "def plot_faces(faces, n):\n",
    "    for i in range(n * n):\n",
    "        # define subplot\n",
    "        pyplot.subplot(n, n, 1 + i)\n",
    "        # turn off axis\n",
    "        pyplot.axis('off')\n",
    "        # plot raw pixel data\n",
    "        pyplot.imshow(faces[i].astype('uint8'))\n",
    "    pyplot.show()\n",
    "\n",
    "# load the face dataset\n",
    "data = load('img_align_celeba_128.npz')\n",
    "faces = data['arr_0']\n",
    "print('Loaded: ', faces.shape)\n",
    "plot_faces(faces, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(generator, batch, image_grid_rows=1, image_grid_columns=1):\n",
    "    print('Printing Sample image')\n",
    "    #z = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, z_dim))\n",
    "    z = generate_latent_points(latent_dim, n_batch)\n",
    "    gen_imgs = generator.predict(z)\n",
    "\n",
    "    gen_imgs = 0.5 * gen_imgs * 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(image_grid_rows, image_grid_columns, figsize=(4, 4), sharey=True, sharex=True)\n",
    "\n",
    "    cnt = 0\n",
    "    for i in range(image_grid_rows):\n",
    "        for j in range(image_grid_columns):\n",
    "            axs[i, j].imshow(gen_imgs[cnt, :, :, 0])#, cmap='gray')\n",
    "            axs[i, j].axis('off')\n",
    "            cnt += 1\n",
    "    plt.show()\n",
    "    print('Printed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_models[0][0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "n_batch = [16, 16, 16, 8, 4, 4] # [16384, 8192, 8192, 1024, 512, 512]\n",
    "# 10 epochs == 500K images per training phase\n",
    "n_epochs = [1, 8, 8, 10, 10, 10] # [1000, 1000, 2000, 3000, 4000, 6000]\n",
    "train(g_models, d_models, gan_models, dataset, latent_dim, n_epochs, n_epochs, n_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
